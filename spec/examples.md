# APIä½¿ç”¨ç¤ºä¾‹

æœ¬æ–‡æ¡£æä¾›OBDé¡¹ç›®çš„å„ç§ä½¿ç”¨åœºæ™¯ä»£ç ç¤ºä¾‹ã€‚

---

## ğŸ“‹ åŸºç¡€ç¤ºä¾‹

### ç¤ºä¾‹1: åŸºæœ¬æ‰¹å¤„ç†

```python
from obd.models import WorkflowConfig
from obd.processor import WorkflowBatchProcessor

# åˆ›å»ºé…ç½®
config = WorkflowConfig(
    api_key="app-your-api-key",
    base_url="https://api.dify.ai/v1",
    response_mode="blocking",
    timeout=60,
    user="batch_processor_001"
)

# åˆ›å»ºå¤„ç†å™¨
processor = WorkflowBatchProcessor(config)

# æ‰§è¡Œæ‰¹å¤„ç†
results = processor.process_excel(
    excel_path="questions.xlsx",
    question_column="question",
    answer_column="answer",
    comparison_method="keyword",
    delay=0.5
)

# æŸ¥çœ‹ç»“æœ
for qa in results:
    print(f"é—®é¢˜: {qa.question}")
    print(f"æœŸæœ›: {qa.expected_answer}")
    print(f"å®é™…: {qa.workflow_result}")
    print(f"ç»“æœ: {'âœ“' if qa.is_correct else 'âœ—'} ({qa.match_type})")
    print("---")

# è®¡ç®—ç»Ÿè®¡
stats = processor.calculate_statistics(results)
print(f"å‡†ç¡®ç‡: {stats['accuracy']:.1%}")
print(f"æˆåŠŸç‡: {stats['success_rate']:.1%}")
```

### ç¤ºä¾‹2: å¤„ç†å•ä¸ªé—®é¢˜

```python
from obd.models import WorkflowConfig
from obd.processor import WorkflowBatchProcessor

config = WorkflowConfig(api_key="app-your-api-key")
processor = WorkflowBatchProcessor(config)

# å¤„ç†å•ä¸ªé—®é¢˜
qa = processor.process_question(
    question="ä»€ä¹ˆæ˜¯æœºå™¨å­¦ä¹ ï¼Ÿ",
    input_variable_name="query",
    output_variable_name="answer",
    comparison_method="auto"
)

print(f"é—®é¢˜: {qa.question}")
print(f"ç­”æ¡ˆ: {qa.workflow_result}")
print(f"æ˜¯å¦æˆåŠŸ: {'æ˜¯' if not qa.error else 'å¦'}")
if qa.error:
    print(f"é”™è¯¯: {qa.error}")
```

---

## ğŸ¯ é«˜çº§ç¤ºä¾‹

### ç¤ºä¾‹3: è‡ªå®šä¹‰å¯¹æ¯”ç­–ç•¥

```python
from obd.comparator import AnswerComparator
from obd.models import QuestionAnswer

class CustomComparator(AnswerComparator):
    """è‡ªå®šä¹‰ç­”æ¡ˆå¯¹æ¯”å™¨"""

    def compare(self, expected: str, actual: str, method="auto") -> tuple:
        # æ•°å­—ç­”æ¡ˆå¿…é¡»ç²¾ç¡®åŒ¹é…
        if expected.isdigit():
            return self.exact_match(expected, actual), "exact"

        # ä¸­æ–‡é—®é¢˜ä½¿ç”¨å…³é”®è¯åŒ¹é…
        if any('\u4e00' <= char <= '\u9fff' for char in expected):
            return self.keyword_match(expected, actual), "keyword"

        # é»˜è®¤ä½¿ç”¨è‡ªåŠ¨åŒ¹é…
        return super().compare(expected, actual, method)

# ä½¿ç”¨è‡ªå®šä¹‰å¯¹æ¯”å™¨
comparator = CustomComparator()
expected = "579"
actual = "äº”ç™¾ä¸ƒåä¹"

is_match, match_type = comparator.compare(expected, actual)
print(f"åŒ¹é…ç»“æœ: {is_match}, ç±»å‹: {match_type}")
```

### ç¤ºä¾‹4: æ‰¹é‡å¤„ç†ä¼˜åŒ–

```python
import asyncio
import aiohttp
from typing import List, Dict, Any

async def async_api_call(session: aiohttp.ClientSession,
                        config: Dict[str, Any],
                        question: str) -> QuestionAnswer:
    """å¼‚æ­¥APIè°ƒç”¨"""
    url = f"{config['base_url']}/chat-messages"

    payload = {
        "query": question,
        "inputs": {},
        "response_mode": "blocking",
        "user": config["user"]
    }

    headers = {
        'Authorization': f'Bearer {config["api_key"]}',
        'Content-Type': 'application/json'
    }

    try:
        async with session.post(url, json=payload, headers=headers) as response:
            data = await response.json()
            answer = data.get("answer", "")

            return QuestionAnswer(
                question=question,
                expected_answer="",
                workflow_result=answer,
                is_correct=False,  # éœ€è¦åç»­å¯¹æ¯”
                workflow_run_id=data.get("task_id")
            )
    except Exception as e:
        return QuestionAnswer(
            question=question,
            expected_answer="",
            error=str(e)
        )

async def batch_process_async(questions: List[str],
                            config: Dict[str, Any],
                            max_concurrent: int = 3) -> List[QuestionAnswer]:
    """å¼‚æ­¥æ‰¹é‡å¤„ç†"""
    connector = aiohttp.TCPConnector(limit=max_concurrent)

    async with aiohttp.ClientSession(connector=connector) as session:
        tasks = []
        for question in questions:
            task = asyncio.create_task(async_api_call(session, config, question))
            tasks.append(task)

        results = await asyncio.gather(*tasks)
        return results

# ä½¿ç”¨ç¤ºä¾‹
async def main():
    config = {
        "api_key": "app-your-api-key",
        "base_url": "https://api.dify.ai/v1",
        "user": "async_processor"
    }

    questions = [
        "1+1ç­‰äºå‡ ï¼Ÿ",
        "ä¸­å›½çš„é¦–éƒ½æ˜¯å“ªé‡Œï¼Ÿ",
        "5çš„å¹³æ–¹æ˜¯å¤šå°‘ï¼Ÿ"
    ]

    results = await batch_process_async(questions, config)
    print(f"å¤„ç†äº† {len(results)} ä¸ªé—®é¢˜")

    # åç»­å¤„ç†...
    for qa in results:
        print(f"é—®é¢˜: {qa.question}, ç»“æœ: {qa.workflow_result}")

# è¿è¡Œ
# asyncio.run(main())
```

---

## ğŸ”§ é…ç½®ç¤ºä¾‹

### ç¤ºä¾‹5: å¤šç¯å¢ƒé…ç½®

```python
import configparser
from pathlib import Path
from obd.models import WorkflowConfig

def load_config(env: str = "development") -> WorkflowConfig:
    """åŠ è½½ä¸åŒç¯å¢ƒçš„é…ç½®"""
    config_path = Path("config.ini")

    if not config_path.exists():
        # åˆ›å»ºé»˜è®¤é…ç½®
        create_default_config(config_path, env)

    config_parser = configparser.ConfigParser()
    config_parser.read(config_path)

    # æ ¹æ®ç¯å¢ƒé€‰æ‹©é…ç½®èŠ‚
    if env == "production":
        dify_section = "Dify_Production"
    elif env == "staging":
        dify_section = "Dify_Staging"
    else:
        dify_section = "Dify_Development"

    # åŠ è½½é…ç½®
    dify_config = config_parser[dify_section]

    return WorkflowConfig(
        api_key=dify_config.get("api_key"),
        base_url=dify_config.get("base_url"),
        response_mode=dify_config.get("response_mode", "blocking"),
        timeout=dify_config.getint("timeout", 60),
        user=dify_config.get("user", "batch_processor")
    )

def create_default_config(path: Path, env: str):
    """åˆ›å»ºé»˜è®¤é…ç½®æ–‡ä»¶"""
    config_content = f"""[Dify_Development]
api_key = dev-your-api-key
base_url = http://localhost/v1
response_mode = blocking
timeout = 60
user = dev_processor

[Dify_Staging]
api_key = staging-your-api-key
base_url = https://api.staging.dify.ai/v1
response_mode = blocking
timeout = 60
user = staging_processor

[Dify_Production]
api_key = prod-your-api-key
base_url = https://api.dify.ai/v1
response_mode = blocking
timeout = 120
user = prod_processor

[Excel]
file_path = questions.xlsx
question_column = question
answer_column = answer

[Workflow]
input_variable_name = query
output_variable_name = answer
comparison_method = auto
delay = 0.5

[Output]
file_path = results.xlsx
"""

    with open(path, 'w', encoding='utf-8') as f:
        f.write(config_content)

# ä½¿ç”¨ç¤ºä¾‹
config = load_config("production")
processor = WorkflowBatchProcessor(config)
```

### ç¤ºä¾‹6: åŠ¨æ€é…ç½®

```python
from obd.models import WorkflowConfig
from typing import Optional

class DynamicWorkflowConfig(WorkflowConfig):
    """åŠ¨æ€é…ç½®ç±»"""

    def __init__(self, api_key: str, **kwargs):
        super().__init__(api_key=api_key, **kwargs)
        self._retry_count = kwargs.get('retry_count', 3)
        self._retry_delay = kwargs.get('retry_delay', 1)

    @property
    def retry_count(self) -> int:
        return self._retry_count

    @retry_count.setter
    def retry_count(self, value: int):
        self._retry_count = max(1, value)

    def validate(self) -> bool:
        """éªŒè¯é…ç½®æœ‰æ•ˆæ€§"""
        if not self.api_key.startswith(('app-', 'workflow-')):
            raise ValueError("APIå¯†é’¥æ ¼å¼æ— æ•ˆ")

        if self.timeout <= 0:
            raise ValueError("è¶…æ—¶æ—¶é—´å¿…é¡»å¤§äº0")

        if self.delay < 0:
            raise ValueError("å»¶è¿Ÿæ—¶é—´ä¸èƒ½ä¸ºè´Ÿæ•°")

        return True

# ä½¿ç”¨ç¤ºä¾‹
try:
    config = DynamicWorkflowConfig(
        api_key="app-your-api-key",
        base_url="https://api.dify.ai/v1",
        timeout=60,
        delay=0.5,
        retry_count=5  # è‡ªå®šä¹‰é‡è¯•æ¬¡æ•°
    )

    config.validate()
    processor = WorkflowBatchProcessor(config)
    print("é…ç½®éªŒè¯é€šè¿‡")

except ValueError as e:
    print(f"é…ç½®éªŒè¯å¤±è´¥: {e}")
```

---

## ğŸ“Š ç»Ÿè®¡å’Œåˆ†æç¤ºä¾‹

### ç¤ºä¾‹7: è¯¦ç»†ç»Ÿè®¡åˆ†æ

```python
import pandas as pd
from obd.processor import WorkflowBatchProcessor
from obd.models import WorkflowConfig

def analyze_results(results: List[QuestionAnswer]) -> Dict[str, Any]:
    """è¯¦ç»†åˆ†æå¤„ç†ç»“æœ"""

    # åŸºç¡€ç»Ÿè®¡
    stats = {
        "total": len(results),
        "successful": sum(1 for r in results if not r.error),
        "failed": sum(1 for r in results if r.error),
        "correct": sum(1 for r in results if r.is_correct),
        "incorrect": sum(1 for r in results if not r.is_correct and not r.error)
    }

    # æŒ‰åŒ¹é…ç±»å‹ç»Ÿè®¡
    match_stats = {}
    for r in results:
        if r.match_type:
            match_stats[r.match_type] = match_stats.get(r.match_type, 0) + 1

    # æŒ‰é—®é¢˜é•¿åº¦åˆ†æ
    length_stats = {
        "avg_question_length": sum(len(r.question) for r in results) / len(results),
        "avg_answer_length": sum(len(r.workflow_result or "") for r in results) / len(results)
    }

    # é”™è¯¯åˆ†æ
    error_types = {}
    for r in results:
        if r.error:
            error_type = r.error.split(":")[0]
            error_types[error_type] = error_types.get(error_type, 0) + 1

    return {
        "basic_stats": stats,
        "match_types": match_stats,
        "length_stats": length_stats,
        "error_analysis": error_types
    }

# ä½¿ç”¨ç¤ºä¾‹
config = WorkflowConfig(api_key="app-your-api-key")
processor = WorkflowBatchProcessor(config)

# å¤„ç†æ•°æ®
results = processor.process_excel("questions.xlsx")

# åˆ†æç»“æœ
analysis = analyze_results(results)

print("=== è¯¦ç»†åˆ†ææŠ¥å‘Š ===")
print(f"æ€»æ•°é‡: {analysis['basic_stats']['total']}")
print(f"æˆåŠŸç‡: {analysis['basic_stats']['successful']/analysis['basic_stats']['total']:.1%}")
print(f"å‡†ç¡®ç‡: {analysis['basic_stats']['correct']/analysis['basic_stats']['total']:.1%}")
print("\nåŒ¹é…ç±»å‹åˆ†å¸ƒ:")
for match_type, count in analysis['match_types'].items():
    print(f"  {match_type}: {count}")

if analysis['error_analysis']:
    print("\né”™è¯¯ç±»å‹åˆ†å¸ƒ:")
    for error_type, count in analysis['error_analysis'].items():
        print(f"  {error_type}: {count}")
```

### ç¤ºä¾‹8: ç»“æœå¯è§†åŒ–

```python
import matplotlib.pyplot as plt
from obd.processor import WorkflowBatchProcessor

def plot_results(results: List[QuestionAnswer]):
    """å¯è§†åŒ–å¤„ç†ç»“æœ"""

    # å‡†å¤‡æ•°æ®
    labels = ['Correct', 'Incorrect', 'Failed']
    sizes = [
        sum(1 for r in results if r.is_correct),
        sum(1 for r in results if not r.is_correct and not r.error),
        sum(1 for r in results if r.error)
    ]

    # åˆ›å»ºé¥¼å›¾
    fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(12, 5))

    # ç»“æœåˆ†å¸ƒ
    ax1.pie(sizes, labels=labels, autopct='%1.1f%%', startangle=90)
    ax1.set_title('Results Distribution')

    # åŒ¹é…ç±»å‹åˆ†å¸ƒ
    match_types = {}
    for r in results:
        if r.match_type:
            match_types[r.match_type] = match_types.get(r.match_type, 0) + 1

    ax2.bar(match_types.keys(), match_types.values())
    ax2.set_title('Match Types Distribution')
    ax2.set_xlabel('Match Type')
    ax2.set_ylabel('Count')

    plt.tight_layout()
    plt.savefig('results_analysis.png')
    plt.close()

# ä½¿ç”¨ç¤ºä¾‹
config = WorkflowConfig(api_key="app-your-api-key")
processor = WorkflowBatchProcessor(config)
results = processor.process_excel("questions.xlsx")
plot_results(results)
print("å›¾è¡¨å·²ä¿å­˜ä¸º results_analysis.png")
```

---

## ğŸ› ï¸ é”™è¯¯å¤„ç†ç¤ºä¾‹

### ç¤ºä¾‹9: å®Œå–„çš„é”™è¯¯å¤„ç†

```python
import logging
from obd.models import WorkflowConfig, QuestionAnswer
from obd.processor import WorkflowBatchProcessor

# é…ç½®æ—¥å¿—
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(levelname)s - %(message)s'
)
logger = logging.getLogger(__name__)

def robust_batch_processing(config: WorkflowConfig,
                           excel_path: str,
                           max_retries: int = 3) -> List[QuestionAnswer]:
    """å¥å£®çš„æ‰¹å¤„ç†"""
    processor = WorkflowBatchProcessor(config)
    all_results = []

    try:
        # åŠ è½½Excelæ–‡ä»¶
        df = processor.load_excel(excel_path)

        # åˆ†æ‰¹å¤„ç†ä»¥é¿å…å†…å­˜é—®é¢˜
        batch_size = 100
        total_batches = (len(df) + batch_size - 1) // batch_size

        for batch_idx in range(total_batches):
            start_row = batch_idx * batch_size
            end_row = min((batch_idx + 1) * batch_size, len(df))

            logger.info(f"å¤„ç†æ‰¹æ¬¡ {batch_idx + 1}/{total_batches} "
                       f"(è¡Œ {start_row + 1}-{end_row})")

            # å¤„ç†å½“å‰æ‰¹æ¬¡
            try:
                batch_results = processor.process_excel(
                    excel_path=excel_path,
                    start_row=start_row,
                    end_row=end_row,
                    delay=1.0  # å¢åŠ å»¶è¿Ÿé¿å…é™æµ
                )

                # é‡è¯•å¤±è´¥çš„é¡¹
                for qa in batch_results:
                    if qa.error and max_retries > 0:
                        logger.warning(f"é‡è¯•é—®é¢˜: {qa.question[:50]}...")
                        for retry in range(max_retries):
                            try:
                                new_qa = processor.process_question(qa.question)
                                if not new_qa.error:
                                    qa = new_qa
                                    break
                            except Exception as e:
                                logger.error(f"é‡è¯• {retry + 1} å¤±è´¥: {e}")

                all_results.extend(batch_results)

                # è®°å½•æ‰¹æ¬¡ç»Ÿè®¡
                batch_success = sum(1 for r in batch_results if not r.error)
                logger.info(f"æ‰¹æ¬¡å®Œæˆ: {batch_success}/{len(batch_results)} æˆåŠŸ")

            except Exception as e:
                logger.error(f"æ‰¹æ¬¡ {batch_idx + 1} å¤„ç†å¤±è´¥: {e}")
                # ç»§ç»­å¤„ç†ä¸‹ä¸€æ‰¹æ¬¡
                continue

    except Exception as e:
        logger.error(f"æ‰¹å¤„ç†å¤±è´¥: {e}")
        raise

    # æœ€ç»ˆç»Ÿè®¡
    total = len(all_results)
    successful = sum(1 for r in all_results if not r.error)

    logger.info(f"å¤„ç†å®Œæˆ: {successful}/{total} æˆåŠŸ "
               f"({successful/total:.1%})")

    return all_results

# ä½¿ç”¨ç¤ºä¾‹
try:
    config = WorkflowConfig(api_key="app-your-api-key")
    results = robust_batch_processing(config, "questions.xlsx", max_retries=2)

    # ä¿å­˜ç»“æœ
    processor = WorkflowBatchProcessor(config)
    stats = processor.calculate_statistics(results)
    processor.save_results(results, stats, "robust_results.xlsx")

except Exception as e:
    logger.error(f"ç¨‹åºå¼‚å¸¸é€€å‡º: {e}")
```

---

## ğŸ“ æ›´æ–°æ—¥å¿—

| ç‰ˆæœ¬ | æ—¥æœŸ | æ›´æ–°å†…å®¹ |
|------|------|----------|
| v0.1.0 | 2025-12-29 | åˆå§‹ç‰ˆæœ¬ï¼Œæä¾›åŸºç¡€å’Œé«˜çº§ä½¿ç”¨ç¤ºä¾‹ |
| v0.1.1 | 2025-12-29 | å¢åŠ å¼‚æ­¥å¤„ç†ã€é”™è¯¯å¤„ç†ã€ç»Ÿè®¡åˆ†æç¤ºä¾‹ |

---

## ğŸ“ ç›¸å…³èµ„æº

- [å¿«é€Ÿå¼€å§‹æŒ‡å—](quickstart.md) - 5åˆ†é’Ÿå¿«é€Ÿä¸Šæ‰‹
- [APIæ¥å£æ–‡æ¡£](api.md) - å®Œæ•´APIæ–‡æ¡£
- [æ•°æ®æ¨¡å‹æ–‡æ¡£](models.md) - æ•°æ®ç»“æ„è¯´æ˜
- [é—®é¢˜æ’æŸ¥æŒ‡å—](troubleshooting.md) - å¸¸è§é—®é¢˜è§£å†³æ–¹æ¡ˆ